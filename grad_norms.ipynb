{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @contextmanager\n",
    "# def suppress_output():\n",
    "#     with open(os.devnull, 'w') as fnull:\n",
    "#         old_stdout = sys.stdout\n",
    "#         old_stderr = sys.stderr\n",
    "#         sys.stdout = fnull\n",
    "#         sys.stderr = fnull\n",
    "#         try:\n",
    "#             yield\n",
    "#         finally:\n",
    "#             sys.stdout = old_stdout\n",
    "#             sys.stderr = old_stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"training.log\"),  \n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sapr7y/noisy_ssm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-15 19:35:23.100235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-15 19:35:23.119032: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-15 19:35:23.124730: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-15 19:35:23.139595: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-15 19:35:24.086377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoTokenizer, TrainingArguments, AutoModelForCausalLM\n",
    "from mamba_trainer.data import DataModule\n",
    "from mamba_trainer.trainer import MambaTrainer, GradientCallback\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "tokenizer.eos_token = \"<|endoftext|>\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    target_modules=[\"x_proj\", \"embeddings\", \"in_proj\", \"out_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MambaForCausalLM(\n",
       "      (backbone): MambaModel(\n",
       "        (embeddings): lora.Embedding(\n",
       "          (base_layer): Embedding(50280, 768)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Identity()\n",
       "          )\n",
       "          (lora_A): ModuleDict()\n",
       "          (lora_B): ModuleDict()\n",
       "          (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 16x50280 (cuda:0)])\n",
       "          (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 768x16 (cuda:0)])\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x MambaBlock(\n",
       "            (norm): MambaRMSNorm(768, eps=1e-05)\n",
       "            (mixer): MambaMixer(\n",
       "              (conv1d): Conv1d(1536, 1536, kernel_size=(4,), stride=(1,), padding=(3,), groups=1536)\n",
       "              (act): SiLU()\n",
       "              (in_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (x_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=80, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=80, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (dt_proj): Linear(in_features=48, out_features=1536, bias=True)\n",
       "              (out_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_f): MambaRMSNorm(768, eps=1e-05)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50280, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,796,608 || all params: 132,931,968 || trainable%: 2.86\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params:,} || all params: {all_param:,} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sapr7y/noisy_ssm/.venv/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    output_dir=\"model\",\n",
    "    logging_dir=\"logs\",\n",
    "    evaluation_strategy=\"no\", \n",
    "    logging_steps=1,\n",
    "    save_steps=1,\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/basic_20-70/train.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723739732.375249 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723739732.386345 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723739732.397141 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723739732.412803 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723739732.421329 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723739732.426939 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723739732.443477 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723739732.456109 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1723739732.471926 2047537 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-15 19:35:32.475711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 52101 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:05:00.0, compute capability: 8.0\n",
      "2024-08-15 19:35:33.996875: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/basic_20-70/val.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-15 19:35:35.160134: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_data_module = DataModule(data_path=\"./data/basic_20-70/train.tsv\", tokenizer=tokenizer)\n",
    "train_dataset = train_data_module.dataset\n",
    "val_data_module = DataModule(data_path=\"./data/basic_20-70/val.tsv\", tokenizer=tokenizer)\n",
    "val_dataset = val_data_module.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(trainer, eval_dataset, step):\n",
    "    metrics = trainer.evaluate(eval_dataset)\n",
    "    loss = metrics.get('eval_loss', None)\n",
    "    logger.info(f\"Validation Loss at step {step}: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8619, 'grad_norm': 1.4639662504196167, 'learning_rate': 0.0, 'pre_update_loss': 2.8619091510772705, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:02<36:45,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.4695, 'train_samples_per_second': 2.722, 'train_steps_per_second': 0.68, 'train_loss': 2.8619091510772705, 'pre_update_loss': 2.8619091510772705, 'epoch': 1.0}\n",
      "{'loss': 2.7825, 'grad_norm': 1.142163634300232, 'learning_rate': 0.0, 'pre_update_loss': 2.7824604511260986, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:03<29:45,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.1459, 'train_samples_per_second': 3.491, 'train_steps_per_second': 0.873, 'train_loss': 2.7824604511260986, 'pre_update_loss': 2.7824604511260986, 'epoch': 1.0}\n",
      "{'loss': 2.8572, 'grad_norm': 1.4149364233016968, 'learning_rate': 0.0, 'pre_update_loss': 2.8571767807006836, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:05<33:24,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.835, 'train_samples_per_second': 2.18, 'train_steps_per_second': 0.545, 'train_loss': 2.8571767807006836, 'pre_update_loss': 2.8571767807006836, 'epoch': 1.0}\n",
      "{'loss': 2.8561, 'grad_norm': 1.3130896091461182, 'learning_rate': 0.0, 'pre_update_loss': 2.856112241744995, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:07<30:58,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.3393, 'train_samples_per_second': 2.987, 'train_steps_per_second': 0.747, 'train_loss': 2.856112241744995, 'pre_update_loss': 2.856112241744995, 'epoch': 1.0}\n",
      "{'loss': 2.7542, 'grad_norm': 1.096690058708191, 'learning_rate': 0.0, 'pre_update_loss': 2.7541539669036865, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:09<31:28,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.5762, 'train_samples_per_second': 2.538, 'train_steps_per_second': 0.634, 'train_loss': 2.7541539669036865, 'pre_update_loss': 2.7541539669036865, 'epoch': 1.0}\n",
      "{'loss': 2.5959, 'grad_norm': 0.9770918488502502, 'learning_rate': 0.0, 'pre_update_loss': 2.5959413051605225, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:11<31:57,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.6633, 'train_samples_per_second': 2.405, 'train_steps_per_second': 0.601, 'train_loss': 2.5959413051605225, 'pre_update_loss': 2.5959413051605225, 'epoch': 1.0}\n",
      "{'loss': 3.1706, 'grad_norm': 1.556930422782898, 'learning_rate': 0.0, 'pre_update_loss': 3.1706106662750244, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:13<31:42,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.4068, 'train_samples_per_second': 2.843, 'train_steps_per_second': 0.711, 'train_loss': 3.1706106662750244, 'pre_update_loss': 3.1706106662750244, 'epoch': 1.0}\n",
      "{'loss': 2.7686, 'grad_norm': 1.046669840812683, 'learning_rate': 0.0, 'pre_update_loss': 2.7685508728027344, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:15<33:26,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.9521, 'train_samples_per_second': 2.049, 'train_steps_per_second': 0.512, 'train_loss': 2.7685508728027344, 'pre_update_loss': 2.7685508728027344, 'epoch': 1.0}\n",
      "{'loss': 2.8142, 'grad_norm': 1.0975260734558105, 'learning_rate': 0.0, 'pre_update_loss': 2.814185619354248, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:18<35:35,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2.1528, 'train_samples_per_second': 1.858, 'train_steps_per_second': 0.465, 'train_loss': 2.814185619354248, 'pre_update_loss': 2.814185619354248, 'epoch': 1.0}\n",
      "{'loss': 2.884, 'grad_norm': 1.0256454944610596, 'learning_rate': 0.0, 'pre_update_loss': 2.883972644805908, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:20<34:50,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.6337, 'train_samples_per_second': 2.448, 'train_steps_per_second': 0.612, 'train_loss': 2.883972644805908, 'pre_update_loss': 2.883972644805908, 'epoch': 1.0}\n",
      "{'loss': 2.8162, 'grad_norm': 1.073409080505371, 'learning_rate': 0.0, 'pre_update_loss': 2.8162150382995605, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:21<30:16,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 0.9303, 'train_samples_per_second': 4.3, 'train_steps_per_second': 1.075, 'train_loss': 2.8162150382995605, 'pre_update_loss': 2.8162150382995605, 'epoch': 1.0}\n",
      "{'loss': 2.6104, 'grad_norm': 0.9044678807258606, 'learning_rate': 0.0, 'pre_update_loss': 2.610399007797241, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:23<32:41,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.8502, 'train_samples_per_second': 2.162, 'train_steps_per_second': 0.54, 'train_loss': 2.610399007797241, 'pre_update_loss': 2.610399007797241, 'epoch': 1.0}\n",
      "{'loss': 2.761, 'grad_norm': 1.2777113914489746, 'learning_rate': 0.0, 'pre_update_loss': 2.761019468307495, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 13/1000 [00:26<38:15,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2.6347, 'train_samples_per_second': 1.518, 'train_steps_per_second': 0.38, 'train_loss': 2.761019468307495, 'pre_update_loss': 2.761019468307495, 'epoch': 1.0}\n",
      "{'loss': 2.7473, 'grad_norm': 1.113443374633789, 'learning_rate': 0.0, 'pre_update_loss': 2.7472660541534424, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 14/1000 [00:30<43:10,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3.0103, 'train_samples_per_second': 1.329, 'train_steps_per_second': 0.332, 'train_loss': 2.7472660541534424, 'pre_update_loss': 2.7472660541534424, 'epoch': 1.0}\n",
      "{'loss': 2.8829, 'grad_norm': 1.7518501281738281, 'learning_rate': 0.0, 'pre_update_loss': 2.882904052734375, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 15/1000 [00:33<47:06,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3.1244, 'train_samples_per_second': 1.28, 'train_steps_per_second': 0.32, 'train_loss': 2.882904052734375, 'pre_update_loss': 2.882904052734375, 'epoch': 1.0}\n",
      "{'loss': 2.6482, 'grad_norm': 1.1963293552398682, 'learning_rate': 0.0, 'pre_update_loss': 2.6482226848602295, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 16/1000 [00:37<53:35,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3.4567, 'train_samples_per_second': 1.157, 'train_steps_per_second': 0.289, 'train_loss': 2.6482226848602295, 'pre_update_loss': 2.6482226848602295, 'epoch': 1.0}\n",
      "{'loss': 3.0071, 'grad_norm': 1.822587251663208, 'learning_rate': 0.0, 'pre_update_loss': 3.007148265838623, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 17/1000 [00:41<55:23,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3.2644, 'train_samples_per_second': 1.225, 'train_steps_per_second': 0.306, 'train_loss': 3.007148265838623, 'pre_update_loss': 3.007148265838623, 'epoch': 1.0}\n",
      "{'loss': 2.7929, 'grad_norm': 1.2938666343688965, 'learning_rate': 0.0, 'pre_update_loss': 2.792912483215332, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 18/1000 [00:44<56:06,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3.2777, 'train_samples_per_second': 1.22, 'train_steps_per_second': 0.305, 'train_loss': 2.792912483215332, 'pre_update_loss': 2.792912483215332, 'epoch': 1.0}\n",
      "{'loss': 2.8393, 'grad_norm': 1.2552732229232788, 'learning_rate': 0.0, 'pre_update_loss': 2.839315414428711, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 19/1000 [00:48<57:51,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3.512, 'train_samples_per_second': 1.139, 'train_steps_per_second': 0.285, 'train_loss': 2.839315414428711, 'pre_update_loss': 2.839315414428711, 'epoch': 1.0}\n",
      "{'loss': 2.506, 'grad_norm': 0.8212756514549255, 'learning_rate': 0.0, 'pre_update_loss': 2.506035804748535, 'epoch': 1.0}\n",
      "{'train_runtime': 3.405, 'train_samples_per_second': 1.175, 'train_steps_per_second': 0.294, 'train_loss': 2.506035804748535, 'pre_update_loss': 2.506035804748535, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "grad_callback = GradientCallback()\n",
    "\n",
    "for i in tqdm(range(1000), disable=False):\n",
    "    np.random.seed(None)\n",
    "    ids = np.random.choice(len(train_dataset), size=4, replace=False)\n",
    "    subset = Subset(train_dataset, ids.tolist())\n",
    "    \n",
    "    trainer = MambaTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=subset,\n",
    "            tokenizer=tokenizer,\n",
    "            optimizers=(optimizer, None),\n",
    "            data_collator=train_data_module.data_collator,\n",
    "            callbacks=[grad_callback]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    if grad_callback.step % 20 == 0:\n",
    "        evaluate(trainer=trainer,\n",
    "                     eval_dataset=val_dataset,\n",
    "                     step=grad_callback.step\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
